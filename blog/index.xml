<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Blogs on {code that works}</title>
    <link>https://sadique.io/blog/?utm_source=site&amp;utm_medium=feed</link>
    <description>Recent content in Blogs on {code that works}</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Wed, 19 Nov 2025 17:21:19 -0800</lastBuildDate>
    <atom:link href="https://sadique.io/blog/?utm_source=site&amp;utm_medium=feed" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Flushing Metrics in Dropwizard Commands</title>
      <link>https://sadique.io/blog/2019/08/02/flushing-metrics-in-dropwizard-commands/?utm_source=site&amp;utm_medium=feed</link>
      <pubDate>Fri, 02 Aug 2019 18:19:32 -0700</pubDate>
      
      <guid>https://sadique.io/blog/2019/08/02/flushing-metrics-in-dropwizard-commands/?utm_source=site&amp;utm_medium=feed</guid>
      <description>&lt;p&gt;Users of Dropwizard Metrics will be familiar with &lt;code&gt;ScheduledReporter&lt;/code&gt;  - it is a nice pattern that allows metrics reporting to be off loaded to a different thread which periodically sends out the collected metrics instead of making a network call every time a metric is collected. In most use cases, this works great - especially if you are running a server.&lt;/p&gt;
&lt;p&gt;However, the implementation of &lt;code&gt;ScheduledReporter&lt;/code&gt; comes with an interesting quirk - it reports metrics only on the configured schedule, but does not flush the metrics it has collected after the last flush when the reporter is closed.&lt;/p&gt;
&lt;p&gt;Datadog Metrics wires up ScheduledReporters that you configure as Dropwizard Lifecycle managed entities, guaranteeing that when your application shuts down, the reporter is closed.&lt;/p&gt;
&lt;p&gt;This results in metrics collected immediately before an application is shutdown being discarded. This is especially problematic for Dropwizard commands that have varying run times depending on how much data processing it performs.&lt;/p&gt;
&lt;p&gt;Imagine a Dropwizard command that when run downloads a file and processes it. Suppose the usual run time is in minutes, so you have configured your metric reporter&amp;rsquo;s frequency to be &lt;code&gt;1 minute&lt;/code&gt;, which is reasonable for this command. However, consider the situation where the downloaded file contains no data - the command will finish in seconds, thereby discarding any metric it has collected, as it hasn&amp;rsquo;t ran for long enough for the scheduled reporter&amp;rsquo;s executor to kick in.&lt;/p&gt;
&lt;h2 id=&#34;solution&#34;&gt;Solution&lt;/h2&gt;
&lt;p&gt;If you have the ability to override the specific &lt;code&gt;ScheduledReporter&lt;/code&gt; you are using, you could inherit from it and override the &lt;code&gt;#close()&lt;/code&gt; method to call &lt;code&gt;#report&lt;/code&gt; before issuing &lt;code&gt;#stop&lt;/code&gt;. For example, if you were using the &lt;code&gt;ConsoleReporter&lt;/code&gt;, you could override the method and then use a &lt;a href=&#34;https://docs.oracle.com/javase/tutorial/sound/SPI-intro.html&#34;&gt;Service Provider Interface&lt;/a&gt; to provide your new reporter to Datadog Metrics.&lt;/p&gt;
&lt;p&gt;The SPI goes in the file &lt;code&gt;src/main/resources/META-INF/services/io.dropwizard.metrics.ReporterFactory&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;io.sadique.dropwizard.metrics.flush.CustomReporterFactory
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public class CustomReporterFactory extends BaseReporterFactory {
  @Override
  public ScheduledReporter build(MetricRegistry registry) {
    return FlushingReporter.forRegistry(registry)
      .build();
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you are using a reporter like &lt;code&gt;DataogReporter&lt;/code&gt;, it is hard to override it as the constructor is marked private. In such situations, we can create a wrapper that provides the overridden behavior:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public class FlushOnCloseReporter extends ScheduledReporter  {
  private final ScheduledReporter wrapped;

  public FlushOnCloseReporter(ScheduledReporter wrapped, MetricRegistry registry, String name,
                              MetricFilter filter, TimeUnit rateUnit, TimeUnit durationUnit) {
    super(registry, name, filter, rateUnit, durationUnit);
    this.wrapped = wrapped;
  }

  @Override
  public void report(SortedMap&amp;lt;String, Gauge&amp;gt; gauges, SortedMap&amp;lt;String, Counter&amp;gt; counters,
                     SortedMap&amp;lt;String, Histogram&amp;gt; histograms, SortedMap&amp;lt;String, Meter&amp;gt; meters,
                     SortedMap&amp;lt;String, Timer&amp;gt; timers) {
    wrapped.report(gauges, counters, histograms, meters, timers);
  }

  @Override
  public void start(long period, TimeUnit unit) {
    wrapped.start(period, unit);
  }

  @Override
  public void stop() {
    wrapped.report();
    wrapped.stop();
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And the reporter factory can be modified to wrap the &lt;code&gt;DatadogReporter&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public class CustomReporterFactory extends BaseReporterFactory {
  @Override
  public ScheduledReporter build(MetricRegistry registry) {
    DatadogReporter consoleReporter = DatadogReporter.forRegistry(registry)
      .filter(getFilter())
      .convertDurationsTo(getDurationUnit())
      .convertRatesTo(getRateUnit())
      .build();
    return new FlushOnCloseReporter(consoleReporter, registry, &amp;quot;flush-on-close(DatadogReporter)&amp;quot;,
      getFilter(), getRateUnit(), getDurationUnit());
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This will ensure that reports are always flushed before the reporter is shutdown by Dropwizard lifecycle.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Managing environment lifecycles for Dropwizard Commands</title>
      <link>https://sadique.io/blog/2019/07/28/managing-environment-lifecycles-for-dropwizard-commands/?utm_source=site&amp;utm_medium=feed</link>
      <pubDate>Sun, 28 Jul 2019 18:29:49 -0700</pubDate>
      
      <guid>https://sadique.io/blog/2019/07/28/managing-environment-lifecycles-for-dropwizard-commands/?utm_source=site&amp;utm_medium=feed</guid>
      <description>&lt;p&gt;If you have built background workers or other non-server applications with Dropwizard, chances are that you used the Dropwizard Command pattern. In fact, even the sever you wrote with Dropwizard executes a command - specifically &lt;code&gt;io.dropwizard.cli.ServerCommand&lt;/code&gt;. While the server command is great, sometimes you want to build applications that have all the goodies that Dropwizard offers, but you dont want to start a server. Managing Lifecycles is one example of a Dropwizard feature that works great for server applications, but needs some tweaking to get working for non-server commands.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s take the following example. We have the simplest Dropwizard command below. It doesn&amp;rsquo;t do much, except print some logs and sleep for a second in between.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public class WaitingCommand extends EnvironmentCommand&amp;lt;AppConfiguration&amp;gt; {

  public WaitingCommand(Application&amp;lt;AppConfiguration&amp;gt; application) {
    super(application, &amp;quot;wait&amp;quot;, &amp;quot;Wait for a second.&amp;quot;);
  }

  @Override
  protected void run(Environment environment, Namespace namespace, AppConfiguration configuration) throws Exception {
    Logger.getInstance(getClass()).info(&amp;quot;Starting command&amp;quot;);
    try {
      Thread.sleep(1000);
    } catch (InterruptedException e) {
      e.printStackTrace();
    }
    Logger.getInstance(getClass()).info(&amp;quot;Finished running command&amp;quot;);
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can wire this to our application.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public class MetricsApplication extends Application&amp;lt;AppConfiguration&amp;gt; {
  public static void main(String[] args) throws Exception {
    new MetricsApplication().run(args);
  }

  @Override
  public void run(AppConfiguration configuration, Environment environment) throws Exception {

  }

  @Override
  public void initialize(Bootstrap&amp;lt;AppConfiguration&amp;gt; bootstrap) {
    bootstrap.addCommand(new WaitingCommand(this));

    bootstrap.setConfigurationSourceProvider(new ResourceConfigurationSourceProvider());
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;When our application runs with the &lt;code&gt;wait&lt;/code&gt; command (i.e. we invoke it as &lt;code&gt;java -jar app.jar wait config.yml&lt;/code&gt;), it does the little work we asked it to do.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;INFO  [2019-07-29 01:42:43,703] org.eclipse.jetty.util.log: Logging initialized @2699ms to org.eclipse.jetty.util.log.Slf4jLog
INFO  [2019-07-29 01:42:43,952] io.dropwizard.server.DefaultServerFactory: Registering jersey handler with root path prefix: /
INFO  [2019-07-29 01:42:43,957] io.dropwizard.server.DefaultServerFactory: Registering admin handler with root path prefix: /
INFO  [2019-07-29 01:42:43,960] io.sadique.dropwizard.WaitingCommand: Starting command
INFO  [2019-07-29 01:42:44,966] io.sadique.dropwizard.WaitingCommand: Finished running command
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;adding-a-lifecycle&#34;&gt;Adding a lifecycle&lt;/h2&gt;
&lt;p&gt;Let&amp;rsquo;s try adding an object whose lifecycle we intend to be managed by Dropwizard. Again, this entity in the example doesn&amp;rsquo;t do much - except log when it is started and stopped by Dropwizard.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;import io.dropwizard.lifecycle.Managed;
import org.apache.log4j.Logger;

public class ManagedObject implements Managed {
  @Override
  public void start() throws Exception {
    Logger.getInstance(getClass()).info(&amp;quot;Starting managed object&amp;quot;);
  }

  @Override
  public void stop() throws Exception {
    Logger.getInstance(getClass()).info(&amp;quot;Stopping managed object&amp;quot;);
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We will of course need to tell Dropwizard to manage this object:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;
  @Override
  public void run(AppConfiguration configuration, Environment environment) throws Exception {
    environment.lifecycle().manage(new ManagedObject());
  }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;When the application is run with the &lt;code&gt;wait&lt;/code&gt; command, the log looks like:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;INFO  [2019-07-29 01:50:28,510] org.eclipse.jetty.util.log: Logging initialized @1640ms to org.eclipse.jetty.util.log.Slf4jLog
INFO  [2019-07-29 01:50:28,640] io.dropwizard.server.DefaultServerFactory: Registering jersey handler with root path prefix: /
INFO  [2019-07-29 01:50:28,642] io.dropwizard.server.DefaultServerFactory: Registering admin handler with root path prefix: /
INFO  [2019-07-29 01:50:28,647] io.sadique.dropwizard.WaitingCommand: Starting command
INFO  [2019-07-29 01:50:29,649] io.sadique.dropwizard.WaitingCommand: Finished running command
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Looks like the object we expected Dropwizard to start and stop was ignored. What if we run the application with the &lt;code&gt;server&lt;/code&gt; command?&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;INFO  [2019-07-29 02:09:17,067] org.eclipse.jetty.setuid.SetUIDListener: Opened application@680a66dd{HTTP/1.1,[http/1.1]}{0.0.0.0:8080}
INFO  [2019-07-29 02:09:17,067] org.eclipse.jetty.setuid.SetUIDListener: Opened admin@2dd8239{HTTP/1.1,[http/1.1]}{0.0.0.0:8081}
INFO  [2019-07-29 02:09:17,126] org.eclipse.jetty.server.Server: jetty-9.4.z-SNAPSHOT
INFO  [2019-07-29 02:09:17,143] io.sadique.dropwizard.ManagedObject: Starting managed object
...
...
...
INFO  [2019-07-29 02:09:21,747] org.eclipse.jetty.server.AbstractConnector: Stopped admin@2dd8239{HTTP/1.1,[http/1.1]}{0.0.0.0:8081}
INFO  [2019-07-29 02:09:21,751] org.eclipse.jetty.server.handler.ContextHandler: Stopped i.d.j.MutableServletContextHandler@2ee83775{/,null,UNAVAILABLE}
INFO  [2019-07-29 02:09:21,756] org.eclipse.jetty.server.handler.ContextHandler: Stopped i.d.j.MutableServletContextHandler@19382338{/,null,UNAVAILABLE}
INFO  [2019-07-29 02:09:21,760] io.sadique.dropwizard.ManagedObject: Stopping managed object
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The server seems to manage the lifecycle of the object as expected. Why is it the case that server command can manage the lifecycle, but our custom command can&amp;rsquo;t?&lt;/p&gt;
&lt;p&gt;It turns out, it is not enough to register an entity whose lifecycle needs to be managed, someone needs to attach a lifecycle container to the &lt;code&gt;LifecycleEnvironment&lt;/code&gt;. It is not an issue for the server command because it builds a server using &lt;code&gt;io.dropwizard.server.AbstractServerFactory#buildServer&lt;/code&gt;, which in turn &lt;a href=&#34;https://github.com/dropwizard/dropwizard/blob/master/dropwizard-core/src/main/java/io/dropwizard/server/AbstractServerFactory.java#L611&#34;&gt;attaches the container&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;building-a-lifecyclemanagedcommand&#34;&gt;Building a LifecycleManagedCommand&lt;/h2&gt;
&lt;p&gt;We can mimic the behavior of the server by constructing our own &lt;code&gt;ContainerLifecycle&lt;/code&gt; and starting it before our command performs it&amp;rsquo;s actions. This pattern can be generalized as a &lt;code&gt;LifecycleManagedCommand&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public abstract class LifecycleManagedCommand&amp;lt;T extends Configuration&amp;gt; extends EnvironmentCommand&amp;lt;T&amp;gt; {

  private final ContainerLifeCycle containerLifeCycle;

  public LifecycleManagedCommand(Application&amp;lt;T&amp;gt; application, String name, String description) {
    super(application, name, description);
    containerLifeCycle = new ContainerLifeCycle();
  }

  @Override
  protected void run(Environment environment, Namespace namespace, T configuration) throws Exception {
    environment.lifecycle().getManagedObjects().stream().forEach(mo -&amp;gt; containerLifeCycle.addBean(mo));
    ShutdownThread.register(containerLifeCycle);
    containerLifeCycle.start();

    runManaged(environment, namespace, configuration);

    containerLifeCycle.stop();
  }

  abstract void runManaged(Environment environment, Namespace namespace, T configuration);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This command ensures that:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A new &lt;code&gt;ContainerLifeCycle&lt;/code&gt; is built before running the command.&lt;/li&gt;
&lt;li&gt;Every managed object registered with the Lifecycle is added to the container.&lt;/li&gt;
&lt;li&gt;The container is started and registered with &lt;code&gt;ShutdownThread&lt;/code&gt;, which is Dropwizard&amp;rsquo;s shut down hook.&lt;/li&gt;
&lt;li&gt;The container is stopped after the command performs it&amp;rsquo;s action.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We can now now modify &lt;code&gt;WaitCommand&lt;/code&gt; to use this pattern.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;public class WaitingCommand extends LifecycleManagedCommand&amp;lt;AppConfiguration&amp;gt; {

  public WaitingCommand(Application&amp;lt;AppConfiguration&amp;gt; application) {
    super(application, &amp;quot;wait&amp;quot;, &amp;quot;Wait for a second.&amp;quot;);
  }

  @Override
  protected void runManaged(Environment environment, Namespace namespace, AppConfiguration configuration) {
    Logger.getInstance(getClass()).info(&amp;quot;Starting command&amp;quot;);
    try {
      Thread.sleep(1000);
    } catch (InterruptedException e) {
      e.printStackTrace();
    }
    Logger.getInstance(getClass()).info(&amp;quot;Finished running command&amp;quot;);
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With this change, we can see that Dropwizard correctly handles the lifecycle when the &lt;code&gt;wait&lt;/code&gt; command is executed.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;INFO  [2019-07-29 02:26:34,560] io.dropwizard.server.DefaultServerFactory: Registering jersey handler with root path prefix: /
INFO  [2019-07-29 02:26:34,563] io.dropwizard.server.DefaultServerFactory: Registering admin handler with root path prefix: /
INFO  [2019-07-29 02:26:34,569] io.sadique.dropwizard.ManagedObject: Starting managed object
INFO  [2019-07-29 02:26:34,569] io.sadique.dropwizard.WaitingCommand: Starting command
INFO  [2019-07-29 02:26:35,575] io.sadique.dropwizard.WaitingCommand: Finished running command
INFO  [2019-07-29 02:26:35,575] io.sadique.dropwizard.ManagedObject: Stopping managed object
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The server command will of course continue to work as expected.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Looking up Enum types and values in Postgres</title>
      <link>https://sadique.io/blog/2019/05/09/looking-up-enum-types-and-values-in-postgres/?utm_source=site&amp;utm_medium=feed</link>
      <pubDate>Thu, 09 May 2019 17:10:23 -0700</pubDate>
      
      <guid>https://sadique.io/blog/2019/05/09/looking-up-enum-types-and-values-in-postgres/?utm_source=site&amp;utm_medium=feed</guid>
      <description>&lt;p&gt;In this blog post, we will explore how Postgres stores Enum types and how to query for Enum types and their values. Postgres&amp;rsquo; Enum, like their counterparts in many programming languags are data types that allow only a predefined set of values to be assigned to them. An interesting difference is that compared to programming languages, Postgres does allow blanks within the values of Enums.&lt;/p&gt;
&lt;p&gt;Postgres Enums are created using the &lt;code&gt;CREATE TYPE&lt;/code&gt; statement. The values are ordered in the order in which they are specified in the &lt;code&gt;CREATE&lt;/code&gt; statement.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;=&amp;gt; CREATE TYPE weather AS ENUM (
  &#39;sunny&#39;, &#39;rainy&#39;, &#39;cloudy&#39;, &#39;snow&#39;
  );

CREATE TYPE

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Postgres stores Enums in the &lt;code&gt;pg_type&lt;/code&gt; catalog. This catalog assigns a &lt;code&gt;typcategory&lt;/code&gt; to every type and Enums &lt;a href=&#34;https://www.postgresql.org/docs/current/catalog-pg-type.html#CATALOG-TYPCATEGORY-TABLE&#34;&gt;have category&lt;/a&gt; &lt;code&gt;E&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;=&amp;gt; SELECT
  *
  FROM pg_type
  WHERE typcategory = &#39;E&#39;;

-[ RECORD 1 ]--+----------
typname        | weather
typnamespace   | 2200
typowner       | 24576
typlen         | 4
typbyval       | t
typtype        | e
typcategory    | E
typispreferred | f
typisdefined   | t
typdelim       | ,
typrelid       | 0
typelem        | 0
typarray       | 41019
typinput       | enum_in
typoutput      | enum_out
typreceive     | enum_recv
typsend        | enum_send
typmodin       | -
typmodout      | -
typanalyze     | -
typalign       | i
typstorage     | p
typnotnull     | f
typbasetype    | 0
typtypmod      | -1
typndims       | 0
typcollation   | 0
typdefaultbin  |
typdefault     |
typacl         |

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This shows us that the name of the enum is &lt;code&gt;weather&lt;/code&gt;. How do we find the possible values of this Enum? Values are stored in the catalog &lt;code&gt;pg_enum&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;=&amp;gt; SELECT
  *
  FROM pg_enum;

 enumtypid | enumsortorder | enumlabel
-----------+---------------+-----------
     41020 |             1 | sunny
     41020 |             2 | rainy
     41020 |             3 | cloudy
     41020 |             4 | snow
(4 rows)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It is worth noting that each of the enum values are in separate rows of the catalog, with each row using the same &lt;code&gt;enumtypid&lt;/code&gt;. The &lt;code&gt;enumtypid&lt;/code&gt; is referring to the &lt;code&gt;oid&lt;/code&gt; of the enum entry in &lt;code&gt;pg_type&lt;/code&gt; catalog. We can verify that we are indeed looking at the same type. &lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;=&amp;gt; SELECT
  *
FROM pg_type
WHERE oid = 41020;

-[ RECORD 1 ]--+----------
typname        | weather
typnamespace   | 2200
typowner       | 24576
typlen         | 4
typbyval       | t
typtype        | e
typcategory    | E
typispreferred | f
typisdefined   | t
typdelim       | ,
typrelid       | 0
typelem        | 0
typarray       | 41019
typinput       | enum_in
typoutput      | enum_out
typreceive     | enum_recv
typsend        | enum_send
typmodin       | -
typmodout      | -
typanalyze     | -
typalign       | i
typstorage     | p
typnotnull     | f
typbasetype    | 0
typtypmod      | -1
typndims       | 0
typcollation   | 0
typdefaultbin  |
typdefault     |
typacl         |
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can use the information we have so far to perform a &lt;code&gt;JOIN&lt;/code&gt; on these catalogs to get all Enum types. To test that values and types are fetched correctly, lets create another enum.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;=&amp;gt; CREATE TYPE transport AS ENUM (
  &#39;bus&#39;, &#39;tram&#39;, &#39;rail&#39;, &#39;ferry&#39;
);

CREATE TYPE
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This enum will create more entries in &lt;code&gt;pg_enum&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;=&amp;gt; SELECT
  *
FROM pg_enum;

 enumtypid | enumsortorder | enumlabel
-----------+---------------+-----------
     41020 |             1 | sunny
     41020 |             2 | rainy
     41020 |             3 | cloudy
     41020 |             4 | snow
     41030 |             1 | bus
     41030 |             2 | tram
     41030 |             3 | rail
     41030 |             4 | ferry
(8 rows)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can now perform the &lt;code&gt;JOIN&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;=&amp;gt; SELECT
  type.typname,
  enum.enumlabel AS value
FROM pg_enum AS enum
JOIN pg_type AS type
  ON (type.oid = enum.enumtypid)
GROUP BY enum.enumlabel,
         type.typname;

  typname  | value
-----------+--------
 weather   | cloudy
 transport | ferry
 transport | bus
 transport | tram
 transport | rail
 weather   | rainy
 weather   | sunny
 weather   | snow
(8 rows)

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This query needs a &lt;code&gt;GROUP BY&lt;/code&gt; due to the fact that there are multiple rows representing a single Enum&amp;rsquo;s values.&lt;/p&gt;
&lt;p&gt;This result gives us everything we want in most cases. But sometimes we want to get a single row with an Enum and all it&amp;rsquo;s values. This can be accomplished by the use of Postgres&amp;rsquo; &lt;a href=&#34;https://www.postgresql.org/docs/9.0/functions-aggregate.html&#34;&gt;&lt;code&gt;string_agg&lt;/code&gt;&lt;/a&gt; function.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;=&amp;gt; SELECT
  type.typname AS name,
  string_agg(enum.enumlabel, &#39;|&#39;) AS value
FROM pg_enum AS enum
JOIN pg_type AS type
  ON (type.oid = enum.enumtypid)
GROUP BY type.typname;

   name    |          value
-----------+-------------------------
 transport | bus|tram|rail|ferry
 weather   | sunny|rainy|cloudy|snow
(2 rows)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Our choice of &lt;code&gt;|&lt;/code&gt; as the separator is arbitrary, but it is important to remember that Postgres does allow blanks in Enum values and using blank as the separator will lead to unexpected and wrong results. &lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;div class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;
&lt;p&gt;Postgres does not display values of &lt;code&gt;oid&lt;/code&gt; columns of catalogs by default. It has to be explicitly queried for.&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34;&gt;
&lt;p&gt;Being bit hard by this issue is how I learned about this.&amp;#160;&lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>Viewing Sequence ownership information in Postgres</title>
      <link>https://sadique.io/blog/2019/05/07/viewing-sequence-ownership-information-in-postgres/?utm_source=site&amp;utm_medium=feed</link>
      <pubDate>Tue, 07 May 2019 18:04:42 -0700</pubDate>
      
      <guid>https://sadique.io/blog/2019/05/07/viewing-sequence-ownership-information-in-postgres/?utm_source=site&amp;utm_medium=feed</guid>
      <description>&lt;p&gt;This blog post is an exercise in identifying all the &lt;code&gt;sequences&lt;/code&gt; in a PostgreSQL database that is associated with a table column via an &lt;code&gt;OWNED BY&lt;/code&gt; relationship. Figuring out how to do this was harder than it should have been and this journals my understanding of it.&lt;/p&gt;
&lt;p&gt;When I first started looking at this, I ended up at this Stack Overflow &lt;a href=&#34;https://stackoverflow.com/questions/9900346/how-do-you-view-new-sequence-ownership-information-in-postgres-after-using-alter&#34;&gt;answer&lt;/a&gt; from 2012. While that seemed to work, it is fair to say that I had no idea what it did. So, I set out to understand it and hopefully improve it.&lt;/p&gt;
&lt;p&gt;We will start by creating a &lt;code&gt;table&lt;/code&gt; that we will later associate a &lt;code&gt;sequence&lt;/code&gt; with.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;CREATE TABLE users
  (
     id   BIGINT NOT NULL,
     NAME VARCHAR(40) NOT NULL
  );
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next, we will create a sequence that is not going to be owned by any columns - a freehanging sequence.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;CREATE SEQUENCE freehanging;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Postgres stores &lt;code&gt;sequence&lt;/code&gt;s across two different catalogs - &lt;a href=&#34;https://www.postgresql.org/docs/current/catalog-pg-sequence.html&#34;&gt;&lt;code&gt;pg_sequence&lt;/code&gt;&lt;/a&gt; and &lt;a href=&#34;https://www.postgresql.org/docs/current/catalog-pg-class.html&#34;&gt;&lt;code&gt;pg_class&lt;/code&gt;&lt;/a&gt;. Catalog &lt;code&gt;pg_sequence&lt;/code&gt; contains sequence parameters like &lt;code&gt;seqstart&lt;/code&gt;, &lt;code&gt;seqincrement&lt;/code&gt; etc. The rest of the information gets stored in &lt;code&gt;pg_class&lt;/code&gt; catalog with the &lt;code&gt;seqlrelid&lt;/code&gt; column in &lt;code&gt;pg_sequence&lt;/code&gt; pointing to the corresponding &lt;code&gt;pg_class&lt;/code&gt; entry.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;=&amp;gt; \x
Expanded display is on.

=&amp;gt; SELECT *
FROM   pg_sequence;

-[ RECORD 1 ]+--------------------
seqrelid     | 41000
seqtypid     | 20
seqstart     | 1
seqincrement | 1
seqmax       | 9223372036854775807
seqmin       | 1
seqcache     | 1
seqcycle     | f

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;That has the information that Postgres can use, but it does not look particularly useful to a human being. Luckily, Postgres provides a &lt;code&gt;view&lt;/code&gt; named &lt;a href=&#34;https://www.postgresql.org/docs/10/view-pg-sequences.html&#34;&gt;&lt;code&gt;pg_sequences&lt;/code&gt;&lt;/a&gt; that shows us more information.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;=&amp;gt; SELECT *
FROM   pg_sequences;

-[ RECORD 1 ]-+--------------------
schemaname    | public
sequencename  | freehanging
sequenceowner | todo
data_type     | bigint
start_value   | 1
min_value     | 1
max_value     | 9223372036854775807
increment_by  | 1
cycle         | f
cache_size    | 1
last_value    |

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can query &lt;code&gt;pg_class&lt;/code&gt; with our &lt;code&gt;seqrelid&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;=&amp;gt; SELECT *
FROM   pg_class
WHERE  relfilenode = 41000;

-[ RECORD 1 ]-------+------------
relname             | freehanging
relnamespace        | 2200
reltype             | 41001
reloftype           | 0
relowner            | 24576
relam               | 0
relfilenode         | 41000
reltablespace       | 0
relpages            | 1
reltuples           | 1
relallvisible       | 0
reltoastrelid       | 0
relhasindex         | f
relisshared         | f
relpersistence      | p
relkind             | S
relnatts            | 3
relchecks           | 0
relhasoids          | f
relhasrules         | f
relhastriggers      | f
relhassubclass      | f
relrowsecurity      | f
relforcerowsecurity | f
relispopulated      | t
relreplident        | n
relispartition      | f
relrewrite          | 0
relfrozenxid        | 0
relminmxid          | 0
relacl              |
reloptions          |
relpartbound        |

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can create a second sequence we want to associate with the &lt;code&gt;users&lt;/code&gt; table.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;=&amp;gt; CREATE SEQUENCE users_id_seq;

CREATE SEQUENCE
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This will now show up in our queries.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;=&amp;gt; SELECT *
FROM   pg_sequence;

-[ RECORD 1 ]+--------------------
seqrelid     | 41000
seqtypid     | 20
seqstart     | 1
seqincrement | 1
seqmax       | 9223372036854775807
seqmin       | 1
seqcache     | 1
seqcycle     | f
-[ RECORD 2 ]+--------------------
seqrelid     | 41002
seqtypid     | 20
seqstart     | 1
seqincrement | 1
seqmax       | 9223372036854775807
seqmin       | 1
seqcache     | 1
seqcycle     | f

=&amp;gt; SELECT *
FROM   pg_sequences;

-[ RECORD 1 ]-+--------------------
schemaname    | public
sequencename  | freehanging
sequenceowner | todo
data_type     | bigint
start_value   | 1
min_value     | 1
max_value     | 9223372036854775807
increment_by  | 1
cycle         | f
cache_size    | 1
last_value    |
-[ RECORD 2 ]-+--------------------
schemaname    | public
sequencename  | users_id_seq
sequenceowner | todo
data_type     | bigint
start_value   | 1
min_value     | 1
max_value     | 9223372036854775807
increment_by  | 1
cycle         | f
cache_size    | 1
last_value    |

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can perform a &lt;code&gt;join&lt;/code&gt; on these catalogs.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;=&amp;gt; SELECT seqclass.relname,
       seqclass.relfilenode
FROM   pg_class AS seqclass
       JOIN pg_sequence AS seq
         ON ( seq.seqrelid = seqclass.relfilenode );

-[ RECORD 1 ]-------------
relname     | freehanging
relfilenode | 41000
-[ RECORD 2 ]-------------
relname     | users_id_seq
relfilenode | 41002

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can go ahead and associate the new sequence with the &lt;code&gt;users&lt;/code&gt; table by specifying &lt;code&gt;OWNED BY&lt;/code&gt;. By setting &lt;code&gt;OWNED BY&lt;/code&gt;, we are specifying that if the column is dropped, we want the sequence to be dropped as well.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;=&amp;gt; ALTER SEQUENCE users_id_seq OWNED BY users.id;

ALTER SEQUENCE
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This association is recorded by Postgres in the &lt;a href=&#34;https://www.postgresql.org/docs/current/catalog-pg-depend.html&#34;&gt;&lt;code&gt;pg_depend&lt;/code&gt;&lt;/a&gt; catalog, using an &lt;code&gt;a&lt;/code&gt; dependency type.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;DEPENDENCY_AUTO (a)&lt;/p&gt;
&lt;p&gt;The dependent object can be dropped separately from the referenced object, and should be automatically dropped (regardless of RESTRICT or CASCADE mode) if the referenced object is dropped. Example: a named constraint on a table is made autodependent on the table, so that it will go away if the table is dropped.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;=&amp;gt; SELECT *
FROM   pg_depend
WHERE  objid = 41002
       AND deptype = &#39;a&#39;;

-[ RECORD 1 ]------
classid     | 1259
objid       | 41002
objsubid    | 0
refclassid  | 1259
refobjid    | 40997
refobjsubid | 1
deptype     | a

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can also verify that the &lt;code&gt;freehanging&lt;/code&gt; sequence has no dependencies of type &lt;code&gt;a&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;=&amp;gt; SELECT *
FROM   pg_depend
WHERE  objid = 41000
       AND deptype = &#39;a&#39;;

(0 rows)

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now that we have a dependency identified for this relationship, we can verify that the dependency is indeed with the &lt;code&gt;users&lt;/code&gt; table. For this, we will query using the dependency&amp;rsquo;s &lt;code&gt;refobjid&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;=&amp;gt; SELECT *
FROM   pg_class
WHERE  relfilenode = 40997;

-[ RECORD 1 ]-------+------
relname             | users
relnamespace        | 2200
reltype             | 40999
reloftype           | 0
relowner            | 24576
relam               | 0
relfilenode         | 40997
reltablespace       | 0
relpages            | 0
reltuples           | 0
relallvisible       | 0
reltoastrelid       | 0
relhasindex         | f
relisshared         | f
relpersistence      | p
relkind             | r
relnatts            | 2
relchecks           | 0
relhasoids          | f
relhasrules         | f
relhastriggers      | f
relhassubclass      | f
relrowsecurity      | f
relforcerowsecurity | f
relispopulated      | t
relreplident        | d
relispartition      | f
relrewrite          | 0
relfrozenxid        | 5021
relminmxid          | 1
relacl              |
reloptions          |
relpartbound        |

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can indeed see that the dependency is on the &lt;code&gt;users&lt;/code&gt; table.&lt;/p&gt;
&lt;p&gt;What about the column associated with this dependency? Postgres stores information about table columns in &lt;a href=&#34;https://www.postgresql.org/docs/current/catalog-pg-attribute.html&#34;&gt;&lt;code&gt;pg_attribute&lt;/code&gt;&lt;/a&gt; catalog. We can verify that the dependency is on the &lt;code&gt;id&lt;/code&gt; column, by querying &lt;code&gt;pg_attribute&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;=&amp;gt; SELECT *
FROM   pg_attribute
WHERE  attrelid = 40997
       AND attnum = 1;

-[ RECORD 1 ]-+------
attrelid      | 40997
attname       | id
atttypid      | 20
attstattarget | -1
attlen        | 8
attnum        | 1
attndims      | 0
attcacheoff   | -1
atttypmod     | -1
attbyval      | t
attstorage    | p
attalign      | d
attnotnull    | t
atthasdef     | f
atthasmissing | f
attidentity   |
attisdropped  | f
attislocal    | t
attinhcount   | 0
attcollation  | 0
attacl        |
attoptions    |
attfdwoptions |
attmissingval |

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can see that the column corresponding to the dependency is indeed &lt;code&gt;id&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Our &lt;code&gt;join&lt;/code&gt; can now be improved to use this information. First, we will add the table name:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;=&amp;gt; SELECT seqclass.relname     AS sequence_name,
       seqclass.relfilenode AS sequenceref,
       dep.refobjid         AS depobjref,
       depclass.relname     AS table_name
FROM   pg_class AS seqclass
       JOIN pg_sequence AS seq
         ON ( seq.seqrelid = seqclass.relfilenode )
       JOIN pg_depend AS dep
         ON ( seq.seqrelid = dep.objid )
       JOIN pg_class AS depclass
         ON ( dep.refobjid = depclass.relfilenode );

-[ RECORD 1 ]+-------------
sequence_name | users_id_seq
sequenceref  | 41002
depobjref    | 40997
table_name    | users

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We have to join twice on the &lt;code&gt;pg_class&lt;/code&gt; catalog - once to get the &lt;code&gt;sequence&lt;/code&gt;&amp;rsquo;s columns and once to get the &lt;code&gt;dependency&lt;/code&gt;&amp;rsquo;s columns. This leaves us with the name of the table and the sequence name.&lt;/p&gt;
&lt;p&gt;Finally, we can perform a join on &lt;code&gt;pg_attribute&lt;/code&gt; to get column information.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;=&amp;gt; SELECT seqclass.relname     AS sequence_name,
       seqclass.relfilenode AS sequenceref,
       dep.refobjid         AS depobjref,
       depclass.relname     AS tabl_ename,
       attrib.attname       AS column_name
FROM   pg_class AS seqclass
       JOIN pg_sequence AS seq
         ON ( seq.seqrelid = seqclass.relfilenode )
       JOIN pg_depend AS dep
         ON ( seq.seqrelid = dep.objid )
       JOIN pg_class AS depclass
         ON ( dep.refobjid = depclass.relfilenode )
       JOIN pg_attribute AS attrib
         ON ( attrib.attnum = dep.refobjsubid
              AND attrib.attrelid = dep.refobjid );

-[ RECORD 1 ]+-------------
sequence_name | users_id_seq
sequenceref   | 41002
depobjref     | 40997
table_name    | users
column_name   | id

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can drop &lt;code&gt;sequenceref&lt;/code&gt; and &lt;code&gt;depobjref&lt;/code&gt; from the result as it is not of particular interest to us when reporting this.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;=&amp;gt; SELECT seqclass.relname AS sequence_name,
       depclass.relname AS table_name,
       attrib.attname   AS column_name
FROM   pg_class AS seqclass
       JOIN pg_sequence AS seq
         ON ( seq.seqrelid = seqclass.relfilenode )
       JOIN pg_depend AS dep
         ON ( seq.seqrelid = dep.objid )
       JOIN pg_class AS depclass
         ON ( dep.refobjid = depclass.relfilenode )
       JOIN pg_attribute AS attrib
         ON ( attrib.attnum = dep.refobjsubid
              AND attrib.attrelid = dep.refobjid );

-[ RECORD 1 ]+-------------
sequenc_ename | users_id_seq
table_name    | users
column_name   | id

&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;postgres-versions-before-10&#34;&gt;Postgres versions before 10&lt;/h2&gt;
&lt;p&gt;The &lt;code&gt;pg_sequence&lt;/code&gt; catalog was introduced in Postgres 10. For versions before 10, we need another way to get hold of the sequence&amp;rsquo;s representation in &lt;code&gt;pg_class&lt;/code&gt; so that we can look up the dependencies. Luckily, &lt;code&gt;pg_class&lt;/code&gt; has a column &lt;code&gt;relkind&lt;/code&gt; that holds this informations. For a sequence, this column will be &lt;code&gt;S&lt;/code&gt;. We can use this in the &lt;code&gt;join&lt;/code&gt; instead of &lt;code&gt;pg_sequence&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;=&amp;gt; SELECT seqclass.relname AS sequence_name,
       depclass.relname AS table_name,
       attrib.attname   as column_name
FROM   pg_class AS seqclass
       JOIN pg_depend AS dep
         ON ( seqclass.relfilenode = dep.objid )
       JOIN pg_class AS depclass
         ON ( dep.refobjid = depclass.relfilenode )
       JOIN pg_attribute AS attrib
         ON ( attrib.attnum = dep.refobjsubid
              AND attrib.attrelid = dep.refobjid )
WHERE  seqclass.relkind = &#39;S&#39;;

-[ RECORD 1 ]-+-------------
sequence_name | users_id_seq
table_name    | users
column_name   | id

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This seems like information that should be surfaced by Postgres in an easier to access way. In fact there is a patch from &lt;a href=&#34;https://web.archive.org/web/20190508035646/https://www.postgresql.org/message-id/1228622212.10877.59.camel%40godzilla.local.scalefeather.com&#34;&gt;2008&lt;/a&gt; that would have introduced this capability. When Postgres 10 introduced the &lt;a href=&#34;https://web.archive.org/web/20190508035646/https://www.postgresql.org/message-id/1228622212.10877.59.camel%40godzilla.local.scalefeather.com&#34;&gt;&lt;code&gt;pg_sequences&lt;/code&gt;&lt;/a&gt; catalog, it stopped at surfacing the id of the user who owns the sequence.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Understanding trailing @ processing in SAS input</title>
      <link>https://sadique.io/blog/2019/03/23/understanding-trailing-@-processing-in-sas-input/?utm_source=site&amp;utm_medium=feed</link>
      <pubDate>Sat, 23 Mar 2019 19:46:08 +0000</pubDate>
      
      <guid>https://sadique.io/blog/2019/03/23/understanding-trailing-@-processing-in-sas-input/?utm_source=site&amp;utm_medium=feed</guid>
      <description>&lt;p&gt;One of the first things I noticed when I started poking around in SAS code is that the &lt;code&gt;input&lt;/code&gt; statement is very powerful, flexible and hence sometimes hard to understand. It can read pretty much anything in to a dataset as long as you tell it what to do.&lt;/p&gt;
&lt;p&gt;The use of trailing &lt;code&gt;@&lt;/code&gt;s to take control of how SAS advances the input pointer is a powerful technique to read from input files where the data is laid out in non-standard formats. In this blog post, we will try to understand how trailing &lt;code&gt;@&lt;/code&gt; processing works with the help of some &lt;code&gt;infile&lt;/code&gt; statement options and the &lt;code&gt;putlog&lt;/code&gt; statement to write to the SAS log.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s take this example from the excellent paper &lt;em&gt;The Input Statement: Where It&amp;rsquo;s @&lt;/em&gt; &lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt; - given an put file where the first variable has to be read beginning from a particular column in the input line based on the value of the second variable.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sas&#34;&gt;Age  Type
23   1
  44 2
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A first pass at trying to do this will result in code like this:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sas&#34;&gt;data ages;
  input @6 type $1.;

  if type=&#39;1&#39; then
    input @1 age 2.;
  else if type=&#39;2&#39; then
    input @3 age 2.;
  drop type;
  datalines;
23   1
  44 2
;
run;

proc print data=ages;
  title &amp;quot;Age read without trailing @&amp;quot;;
run;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The result we get is not what we expect.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sas&#34;&gt;| Obs | Age |
|-----|-----|
| 1   | .   |
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can understand how SAS read this input using the &lt;code&gt;line=&lt;/code&gt; and &lt;code&gt;column=&lt;/code&gt; options of the &lt;code&gt;infile&lt;/code&gt; statement. While the code in the above listing does not explicitly use &lt;code&gt;infile&lt;/code&gt; to point at the &lt;code&gt;datalines&lt;/code&gt;, this can be done when we want to use &lt;code&gt;infile&lt;/code&gt;&amp;rsquo;s options with &lt;code&gt;datalines&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;This is a good time to remind us what the &lt;code&gt;line=&lt;/code&gt; and &lt;code&gt;column=&lt;/code&gt; options of &lt;code&gt;infile&lt;/code&gt; does. From the &lt;a href=&#34;https://documentation.sas.com/?docsetId=lestmtsref&amp;amp;docsetTarget=n1rill4udj0tfun1fvce3j401plo.htm&amp;amp;docsetVersion=9.4&amp;amp;locale=en&#34;&gt;documentation&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;LINE=variable&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;specifies a variable that SAS sets to the line location of the input pointer in the input buffer. As with automatic variables, the LINE= variable is not written to the data set.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;COLUMN=variable&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;names a variable that SAS uses to assign the current column location of the input pointer. As with automatic variables, the COLUMN= variable is not written to the data set.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;We can modify our code to set these options and then print the value of all variables including these options using the &lt;code&gt;_all_&lt;/code&gt; variable that prints the &lt;em&gt;Program Data Vector (PDV)&lt;/em&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sas&#34;&gt;data ages;
  infile datalines line=line column=col;

  input @6 type $1.;
  putlog &amp;quot;After reading type, before reading age: &amp;quot; _all_ ;

  if type=&#39;1&#39; then
    input @1 age 2.;
  else if type=&#39;2&#39; then
    input @3 age 2.;
  putlog &amp;quot;After reading age: &amp;quot; _all_ ;
  putlog &amp;quot;&amp;quot;;

  drop type;
  datalines;
23   1
  44 2
;
run;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;When the code runs, the following can be seen in the SAS logs:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sas&#34;&gt; After reading type, before reading age: line=1 col=7 type=1 age=. _ERROR_=0 _N_=1
 After reading age: line=2 col=3 type=1 age=. _ERROR_=0 _N_=1
 &amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;After &lt;code&gt;type&lt;/code&gt; is read, we can see that the pointer is at line &lt;code&gt;1&lt;/code&gt; and column &lt;code&gt;7&lt;/code&gt;, which makes sense considering that the code instructs SAS to go to column &lt;code&gt;6&lt;/code&gt; and read &lt;code&gt;1&lt;/code&gt; character. But then we notice that when &lt;code&gt;age&lt;/code&gt; is read, the pointer has moved to &lt;code&gt;2&lt;/code&gt; and column &lt;code&gt;3&lt;/code&gt; as instructed in the first branch of the &lt;code&gt;if else&lt;/code&gt; condition. Since there is nothing at column &lt;code&gt;1-2&lt;/code&gt; of line &lt;code&gt;2&lt;/code&gt; in the input, a missing value is stored in &lt;code&gt;age&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;What we want is some way to tell &lt;code&gt;input&lt;/code&gt; to ot move the pointer after the first input statement. This is where the single trailing &lt;code&gt;@&lt;/code&gt; comes in. It intructs &lt;code&gt;input&lt;/code&gt; to stay on the same line for the next &lt;code&gt;input&lt;/code&gt; statement in the &lt;code&gt;data&lt;/code&gt; step. The above listing modified to use trailing &lt;code&gt;@&lt;/code&gt; is as follows:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sas&#34;&gt;data trailing;
  infile datalines line=line column=col;

  input @6 type $1. @;
  putlog &amp;quot;After reading type, before reading age: &amp;quot; _all_ ;

  if type=&#39;1&#39; then
    input @1 age 2.;
  else if type=&#39;2&#39; then
    input @3 age 2.;
  putlog &amp;quot;After reading age: &amp;quot; _all_ ;
  putlog &amp;quot;&amp;quot;;

  drop type;
  datalines;
23   1
  44 2
;
run;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The following log lines are written:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sas&#34;&gt; After reading type, before reading age: line=1 col=7 type=1 age=. _ERROR_=0 _N_=1
 After reading age: line=1 col=3 type=1 age=23 _ERROR_=0 _N_=1
 &amp;quot;
 After reading type, before reading age: line=1 col=7 type=2 age=. _ERROR_=0 _N_=2
 After reading age: line=1 col=5 type=2 age=44 _ERROR_=0 _N_=2
 &amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The log shows that &lt;code&gt;input&lt;/code&gt; stayed on line &lt;code&gt;1&lt;/code&gt; even after reading the &lt;code&gt;type&lt;/code&gt; variable.&lt;/p&gt;
&lt;p&gt;The new dataset has the expected values:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sas&#34;&gt;| Obs | Age |
|-----|-----|
| 1   | 23  |
| 2   | 44  |
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here is another example that you often run in to on the internet when discussing trailing &lt;code&gt;@&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sas&#34;&gt;data  colors;
  infile datalines line=linenum column=col;
  input @1 Var1 $ @8 Var2 $ @;
  putlog &amp;quot;After reading Var1 and Var2: &amp;quot; _all_;

  input @1 Var3 $ @8 Var4 $ ;
  putlog &amp;quot;After reading Var3 and Var4: &amp;quot; _all_;
  putlog &amp;quot;&amp;quot;;

  datalines;
RED    ORANGE  YELLOW  GREEN
BLUE   INDIGO  PURPLE  VIOLET
CYAN   WHITE   FUCSIA  BLACK
GRAY   BROWN   PINK    MAGENTA
;
run;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This results in the following dataset:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sas&#34;&gt;|Obs  | Var1 | Var2   | Var3 | Var4   |
|-----|------|--------|------|--------|
| 1   | RED  | ORANGE | RED  | ORANGE |
| 2   | BLUE | INDIGO | BLUE | INDIGO |
| 3   | CYAN | WHITE  | CYAN | WHITE  |
| 4   | GRAY | BROWN  | GRAY | BROWN  |
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Because of the trailing &lt;code&gt;@&lt;/code&gt; in the first &lt;code&gt;input&lt;/code&gt; statement, the values of &lt;code&gt;Var1&lt;/code&gt; and &lt;code&gt;Var3&lt;/code&gt; for all the observations are the same, as both are read from column &lt;code&gt;1&lt;/code&gt;. Similarly &lt;code&gt;Var2&lt;/code&gt; and &lt;code&gt;Var4&lt;/code&gt; are the same as they are read from column &lt;code&gt;8&lt;/code&gt;.&lt;/p&gt;
&lt;div class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;
&lt;p&gt;The Input Statement: Where It&amp;rsquo;s @. Paper 253-29, SUGI 29 Proceedings.&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Importing the SASUSER datasets in SAS Studio</title>
      <link>https://sadique.io/blog/2019/03/23/importing-the-sasuser-datasets-in-sas-studio/?utm_source=site&amp;utm_medium=feed</link>
      <pubDate>Sat, 23 Mar 2019 18:14:06 +0000</pubDate>
      
      <guid>https://sadique.io/blog/2019/03/23/importing-the-sasuser-datasets-in-sas-studio/?utm_source=site&amp;utm_medium=feed</guid>
      <description>&lt;p&gt;I have been playing around with SAS for the last two weeks. I started with a SAS University Edition running on a VirtualBox instance on my MacBook, but soon realized that it was way more convenient to use a SAS OnDemand account. Having made the switch, I realized that all learning materials made references to and used examples with datsets from a library named &lt;code&gt;SASUSER&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;It was not clear how to get these datasets and use them in SAS Studio. After a bunch of searches, I found &lt;a href=&#34;https://communities.sas.com/t5/SAS-Certification/How-to-get-SASUSER-library-s-data-sets/m-p/306631/highlight/true#M124&#34;&gt;this page&lt;/a&gt; that pointed at data set up scripts for these datasets. The URL it pointed to had of course been repurposed and now redirected to a marketing page. After going back through multiple versions of the page on Internet Archive, I finally managed to find a &lt;a href=&#34;https://web.archive.org/web/20151005165134/http://support.sas.com:80/publishing/cert/basecertguide3.html&#34;&gt;snapshot&lt;/a&gt; that linked to a set up file that worked.&lt;/p&gt;
&lt;p&gt;Here are the steps to use the setup script:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Download the &lt;a href=&#34;https://support.sas.com/content/dam/SAS/support/en/books/data/sampledata.txt&#34;&gt;script&lt;/a&gt;. Depending on the version of the material you are using, you may want to grab an &lt;a href=&#34;https://web.archive.org/web/20150921023746/http://support.sas.com/publishing/cert/sampdata.txt&#34;&gt;older snapshot&lt;/a&gt; from the Internet Archive.&lt;/li&gt;
&lt;li&gt;Rename the file so that it&amp;rsquo;s extension is changed to &lt;code&gt;.sas&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Create a directory under your home directory in SAS Studio, for example &lt;code&gt;sasuser&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Upload the sample data script from step 1 to this folder, using the web interface.&lt;/li&gt;
&lt;li&gt;Create a new SAS source file named &lt;code&gt;libname.sas&lt;/code&gt; with the following content:&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-sas&#34;&gt;libname sasuser &amp;quot;~/sasuser&amp;quot;;
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;Execute this script.&lt;/li&gt;
&lt;li&gt;Now execute the sample data script.&lt;/li&gt;
&lt;li&gt;It should create all the datsets you need in the library named &lt;code&gt;sasuser&lt;/code&gt;. You can verify this using the following script:&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-sas&#34;&gt;proc contents data=sasuser._all_ nods;
run;
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>My talk at GraphQL Summit 2018</title>
      <link>https://sadique.io/blog/2018/11/10/my-talk-at-graphql-summit-2018/?utm_source=site&amp;utm_medium=feed</link>
      <pubDate>Sat, 10 Nov 2018 02:12:47 +0000</pubDate>
      
      <guid>https://sadique.io/blog/2018/11/10/my-talk-at-graphql-summit-2018/?utm_source=site&amp;utm_medium=feed</guid>
      <description>&lt;p&gt;I had the opportunity to give a talk at &lt;a href=&#34;https://summit.graphql.com/&#34;&gt;GraphQL Summit 2018&lt;/a&gt; about the experience of introducing GraphQL for our &lt;a href=&#34;https://graphql.braintreepayments.com/&#34;&gt;Payments API&lt;/a&gt; at &lt;a href=&#34;https://www.braintreepayments.com/&#34;&gt;Braintree&lt;/a&gt;. It was well received, as far as I could tell - I received a lot of nice feedback and had great conversations with members of the community.&lt;/p&gt;
&lt;p&gt;The slides are available here on &lt;a href=&#34;https://speakerdeck.com/sdqali/graphql-for-a-payments-api&#34;&gt;SpeakerDeck&lt;/a&gt;. &lt;del&gt;I will update this post with links to the video of my talk when it becomes available&lt;/del&gt; The video of the talk is available &lt;a href=&#34;https://www.youtube.com/watch?v=NKMDBH0CWHs&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Francesca Guiducci took this photo:&lt;/p&gt;
&lt;blockquote class=&#34;twitter-tweet&#34; data-lang=&#34;en&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;This was the only time I read &amp;quot;java&amp;quot; on the big screen during this conference that was not part of the word &amp;quot;javascript&amp;quot;! Thanks &lt;a href=&#34;https://twitter.com/sdqali?ref_src=twsrc%5Etfw&#34;&gt;@sdqali&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/graphqlsummit?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#graphqlsummit&lt;/a&gt; &lt;a href=&#34;https://t.co/3zAO5TLdYY&#34;&gt;pic.twitter.com/3zAO5TLdYY&lt;/a&gt;&lt;/p&gt;&amp;mdash; Francesca Guiducci (@engfragui) &lt;a href=&#34;https://twitter.com/engfragui/status/1060683834058956800?ref_src=twsrc%5Etfw&#34;&gt;November 9, 2018&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;
</description>
    </item>
    
    <item>
      <title>Formatting Java Instant for resolutions</title>
      <link>https://sadique.io/blog/2018/06/09/formatting-java-instant-for-resolutions/?utm_source=site&amp;utm_medium=feed</link>
      <pubDate>Sat, 09 Jun 2018 18:55:23 +0000</pubDate>
      
      <guid>https://sadique.io/blog/2018/06/09/formatting-java-instant-for-resolutions/?utm_source=site&amp;utm_medium=feed</guid>
      <description>&lt;p&gt;I have had to look up how to format Java&amp;rsquo;s Instant with a given resolution - for example in microseconds or nanoseconds. After fiddling with various formatters, I was happy to finally get this right.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;@Test
public void shouldFormatWith7Decimals() {
  int resolution = 7;
  DateTimeFormatter dateTimeFormatter = new DateTimeFormatterBuilder()
    .appendInstant(resolution)
    .toFormatter();
  Instant instant = Instant.now();
  System.out.println(dateTimeFormatter.format(instant));
}
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>FreeBuilder plugin for IntelliJ</title>
      <link>https://sadique.io/blog/2018/05/05/freebuilder-plugin-for-intellij/?utm_source=site&amp;utm_medium=feed</link>
      <pubDate>Sat, 05 May 2018 05:27:35 +0000</pubDate>
      
      <guid>https://sadique.io/blog/2018/05/05/freebuilder-plugin-for-intellij/?utm_source=site&amp;utm_medium=feed</guid>
      <description>&lt;p&gt;My work uses &lt;a href=&#34;http://freebuilder.inferred.org/&#34;&gt;FreeBuilder&lt;/a&gt; extensively to generate the &lt;a href=&#34;https://en.wikipedia.org/wiki/Builder_pattern&#34;&gt;Builder&lt;/a&gt; pattern for Java classes. In addition to this, we use the generated Builder classes to deserialize the data calsses using Jackson. After a while it became tiresome to type &lt;code&gt;@FreeBuilder&lt;/code&gt; and &lt;code&gt;class Builder extends ...&lt;/code&gt; everywhere. So I decided to write and IntelliJ IDEA plugin that does it for me.&lt;/p&gt;
&lt;p&gt;These are the things I wanted the plugin to do for me:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Annotate the public class from the current file with &lt;code&gt;@FreeBuilder&lt;/code&gt; annotation.&lt;/li&gt;
&lt;li&gt;Create an inner class for the annotated class - this should be a &lt;code&gt;static&lt;/code&gt; class if the annotated class is an &lt;code&gt;abstract&lt;/code&gt; class and a child class if the annotated class is an &lt;code&gt;interface&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Ensure that the generated &lt;code&gt;Builder&lt;/code&gt; class is annotated with &lt;code&gt;@JsonIgnoreProperties(ignoreUnknown=true)&lt;/code&gt; because this is a convention we like to follow.&lt;/li&gt;
&lt;li&gt;Ensure that the parent class gets annotated with &lt;code&gt;@JsonDeserialize(builder=...)&lt;/code&gt; annotation.&lt;/li&gt;
&lt;li&gt;Rebuild the project so that the annotation processing for FreeBuilder runs.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;After poking around the IntelliJ Plugin development documentation, I was able to write a simple enough plugin that does it. For whatever reason, trying to find how to achieve simple things like how to create a new class that you can add as a child to an existing class was painful.&lt;/p&gt;
&lt;p&gt;The plugin is available &lt;a href=&#34;https://plugins.jetbrains.com/plugin/10705-freebuilder-plugin&#34;&gt;here&lt;/a&gt; from the IntelliJ plugin repository and the source code is here on &lt;a href=&#34;https://github.com/sdqali/freebuilder-intellij-plugin&#34;&gt;GitHub&lt;/a&gt;. In addition to the above mentioned features, I wanted to make sure that the annotations gets added only if the annoattion classes were in the classpath of the current module. The plugin also displayes messages when it decides to skip a step because an annotation class was not in the classpath or because nnotations already exist on the class.&lt;/p&gt;
&lt;p&gt;A short demo of the plugin in action is shown below.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://sadique.io/images/freebuilder-plugin-demo.gif&#34; alt=&#34;&amp;ldquo;FreeBuilder Plugin Demo&amp;rdquo;&#34; title=&#34;FreeBuilder Plugin Demo&#34;&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Command line clients for gRPC - polyglot</title>
      <link>https://sadique.io/blog/2018/04/06/command-line-clients-for-grpc-polyglot/?utm_source=site&amp;utm_medium=feed</link>
      <pubDate>Fri, 06 Apr 2018 05:45:08 +0000</pubDate>
      
      <guid>https://sadique.io/blog/2018/04/06/command-line-clients-for-grpc-polyglot/?utm_source=site&amp;utm_medium=feed</guid>
      <description>&lt;p&gt;Polyglot was the second gRPC client that I looked at. One of the things that I liked about it is the fact that it does not need users to generate &lt;code&gt;protoset&lt;/code&gt; files. It generates the protoset files in flight every time it runs. This, combined with the fact that it is written in Java does have a disadvantage - every time the client makes a call, it has to fire up a JVM, generate protosets and make the request.&lt;/p&gt;
&lt;p&gt;You run polyglot by using the distributed polyglot jar. To list all the services available on an endpoint, polyglot can be executed as:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;&amp;gt; java -jar ~/Downloads/polyglot.jar --command=list_services \
  --proto_discovery_root=$PROTO_DISCOVERY_ROOT \
  --deadline_ms=3000
[main] INFO me.dinowernli.grpc.polyglot.Main - Polyglot version: 1.6.0
[main] INFO me.dinowernli.grpc.polyglot.Main - Loaded configuration:

manualflowcontrol.StreamingGreeter -&amp;gt; /Users/sdqali/src/grpc/grpc-java/examples/src/proto/hello_streaming.proto
manualflowcontrol.StreamingGreeter/SayHelloStreaming

routeguide.RouteGuide -&amp;gt; /Users/sdqali/src/grpc/grpc-java/examples/src/proto/route_guide.proto
routeguide.RouteGuide/GetFeature
routeguide.RouteGuide/ListFeatures
routeguide.RouteGuide/RecordRoute
routeguide.RouteGuide/RouteChat

helloworld.Greeter -&amp;gt; /Users/sdqali/src/grpc/grpc-java/examples/src/proto/helloworld.proto
helloworld.Greeter/SayHello
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The command &lt;code&gt;call&lt;/code&gt; can be issued to execute a particular service method:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;echo &amp;quot;{&#39;name&#39;: &#39;World&#39;}&amp;quot; | java -jar ~/Downloads/polyglot.jar --command=call \
  --full_method=helloworld.Greeter/SayHello \
  --endpoint=localhost:50051 \
  --proto_discovery_root=$PROTO_DISCOVERY_ROOT \
  --deadline_ms=3000
[main] INFO me.dinowernli.grpc.polyglot.Main - Polyglot version: 1.6.0
[main] INFO me.dinowernli.grpc.polyglot.Main - Loaded configuration:
[main] INFO me.dinowernli.grpc.polyglot.command.ServiceCall - Creating channel to: localhost:50051
[main] INFO me.dinowernli.grpc.polyglot.command.ServiceCall - Using proto descriptors obtained from protoc
[main] INFO me.dinowernli.grpc.polyglot.command.ServiceCall - Creating dynamic grpc client
[main] INFO me.dinowernli.grpc.polyglot.command.ServiceCall - Making rpc with 1 request(s) to endpoint [localhost:50051]
[main] INFO me.dinowernli.grpc.polyglot.grpc.DynamicGrpcClient - Making unary call
[grpc-default-executor-0] INFO me.dinowernli.grpc.polyglot.io.LoggingStatsWriter - Got response message
{
&amp;quot;message&amp;quot;: &amp;quot;Hello World&amp;quot;
}

[grpc-default-executor-0] INFO me.dinowernli.grpc.polyglot.io.LoggingStatsWriter - Completed rpc with 1 response(s)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Notice how we are passing path to proto files and polyglot executes &lt;code&gt;protoc&lt;/code&gt; on them to get protosets.
With reflection turned ON, we no longer need to provide a path to the proto files.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;echo &amp;quot;{&#39;name&#39;: &#39;World&#39;}&amp;quot; | java -jar ~/Downloads/polyglot.jar --command=call \
  --full_method=helloworld.Greeter/SayHello \
  --endpoint=localhost:50051 \
  --deadline_ms=3000 \
  --use_reflection=true
[main] INFO me.dinowernli.grpc.polyglot.Main - Polyglot version: 1.6.0
[main] INFO me.dinowernli.grpc.polyglot.Main - Loaded configuration:
[main] INFO me.dinowernli.grpc.polyglot.command.ServiceCall - Creating channel to: localhost:50051
[main] INFO me.dinowernli.grpc.polyglot.command.ServiceCall - Using proto descriptors fetched by reflection
[main] INFO me.dinowernli.grpc.polyglot.command.ServiceCall - Creating dynamic grpc client
[main] INFO me.dinowernli.grpc.polyglot.command.ServiceCall - Making rpc with 1 request(s) to endpoint [localhost:50051]
[main] INFO me.dinowernli.grpc.polyglot.grpc.DynamicGrpcClient - Making unary call
[grpc-default-executor-0] INFO me.dinowernli.grpc.polyglot.io.LoggingStatsWriter - Got response message
{
&amp;quot;message&amp;quot;: &amp;quot;Hello World&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;That is nice, except that reflection does not work for listing services.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;java -jar ~/Downloads/polyglot.jar --command=list_services \
  --endpoint=localhost:50051 \
  --deadline_ms=3000 \
  --use_reflection=true
[main] INFO me.dinowernli.grpc.polyglot.Main - Polyglot version: 1.6.0
[main] INFO me.dinowernli.grpc.polyglot.Main - Loaded configuration:
[main] WARN me.dinowernli.grpc.polyglot.Main - Caught top-level exception during command execution
java.lang.IllegalArgumentException: A proto discovery root is required for proto analysis
  at com.google.common.base.Preconditions.checkArgument(Preconditions.java:122)
  at me.dinowernli.grpc.polyglot.protobuf.ProtocInvoker.forConfig(ProtocInvoker.java:36)
  at me.dinowernli.grpc.polyglot.Main.getFileDescriptorSet(Main.java:93)
  at me.dinowernli.grpc.polyglot.Main.main(Main.java:62)
Exception in thread &amp;quot;main&amp;quot; java.lang.RuntimeException: java.lang.IllegalArgumentException: A proto discovery root is required for proto analysis
  at me.dinowernli.grpc.polyglot.Main.main(Main.java:86)
Caused by: java.lang.IllegalArgumentException: A proto discovery root is required for proto analysis
  at com.google.common.base.Preconditions.checkArgument(Preconditions.java:122)
  at me.dinowernli.grpc.polyglot.protobuf.ProtocInvoker.forConfig(ProtocInvoker.java:36)
  at me.dinowernli.grpc.polyglot.Main.getFileDescriptorSet(Main.java:93)
  at me.dinowernli.grpc.polyglot.Main.main(Main.java:62)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This was unexpected, as adding this capability to Polyglot should not be too diffcult, considering that they already support reflection for executing services. This is something that I am interested in implementing.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Command line clients for gRPC - grpcurl</title>
      <link>https://sadique.io/blog/2018/04/04/command-line-clients-for-grpc-grpcurl/?utm_source=site&amp;utm_medium=feed</link>
      <pubDate>Wed, 04 Apr 2018 05:40:08 +0000</pubDate>
      
      <guid>https://sadique.io/blog/2018/04/04/command-line-clients-for-grpc-grpcurl/?utm_source=site&amp;utm_medium=feed</guid>
      <description>&lt;p&gt;We are in the middle of considering replacing JSON over HTTP with gRPC for communication between our internal services. One of my concerns about this was how we would be able to debug and poke around things in a world where we will no longer be able to use cURL. I have been looking at cURL like command line utilities we can use to replace most of the capabilities, if not all of cURL. So far, I have looked at &lt;a href=&#34;https://github.com/fullstorydev/grpcurl&#34;&gt;grpcurl&lt;/a&gt;, &lt;a href=&#34;https://github.com/grpc/grpc/blob/master/doc/command_line_tool.md&#34;&gt;grpc_cli&lt;/a&gt; and &lt;a href=&#34;https://github.com/grpc-ecosystem/polyglot&#34;&gt;polyglot&lt;/a&gt; .In these blog posts, we will try and compare these tools.&lt;/p&gt;
&lt;p&gt;In this example, we will be running the example implementations provided by the &lt;a href=&#34;https://github.com/grpc/grpc-java/tree/master/examples&#34;&gt;grpc-java&lt;/a&gt; project and using the command line tools against the services from these examples. We will also be running these services without enabling reflection.&lt;/p&gt;
&lt;h2 id=&#34;grpcurl&#34;&gt;grpcurl&lt;/h2&gt;
&lt;p&gt;One of the things that immediately struck me when I started looking at grpcurl was how neat it&amp;rsquo;s command line interface was, especially in comparison with that of polyglot. grpcurl is written in Go and expects you to provide &lt;code&gt;protoset&lt;/code&gt; files that contain service descriptors exported from the &lt;code&gt;proto&lt;/code&gt; files of the service.&lt;/p&gt;
&lt;p&gt;For example, for the &lt;code&gt;hello-world&lt;/code&gt; service from the examples, the &lt;code&gt;protoset&lt;/code&gt; files can be generated using:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;&amp;gt; pwd
grpc-java/examples/src/main/proto
&amp;gt; protoc --proto_path=./ \
    --descriptor_set_out=helloworld.protoset \
    --include_imports \
    ./helloworld.proto
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This will produce a &lt;code&gt;protoset&lt;/code&gt; file named &lt;code&gt;helloworld.protoset&lt;/code&gt;. Using this, we can now list the services available:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;&amp;gt; grpcurl -protoset ./helloworld.protoset list
helloworld.Greeter
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can also list all the methods available in a service:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;&amp;gt; grpcurl -protoset ./helloworld.protoset list helloworld.Greeter
SayHello
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There is also a describe command that produces description of a service:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;&amp;gt; grpcurl -protoset ./helloworld.protoset describe helloworld.Greeter
helloworld.Greeter is a service:
{
  &amp;quot;name&amp;quot;: &amp;quot;Greeter&amp;quot;,
  &amp;quot;method&amp;quot;: [
    {
      &amp;quot;name&amp;quot;: &amp;quot;SayHello&amp;quot;,
      &amp;quot;inputType&amp;quot;: &amp;quot;.helloworld.HelloRequest&amp;quot;,
      &amp;quot;outputType&amp;quot;: &amp;quot;.helloworld.HelloReply&amp;quot;,
      &amp;quot;options&amp;quot;: {

      }
    }
  ],
  &amp;quot;options&amp;quot;: {

  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we can execute the method on this service running on a server by specifying the address and the path to the method:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;&amp;gt; grpcurl -plaintext -protoset ./helloworld.protoset -d &#39;{&amp;quot;name&amp;quot;:&amp;quot;World&amp;quot;}&#39; localhost:50051 helloworld.Greeter/SayHello
{
  &amp;quot;message&amp;quot;: &amp;quot;Hello World&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It can also read the JSON data to pass to the server from STDIN, by setting the value of &lt;code&gt;-d&lt;/code&gt; to &lt;code&gt;@&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;&amp;gt; echo &#39;{&amp;quot;name&amp;quot;: &amp;quot;World&amp;quot;}&#39; | grpcurl -plaintext -protoset ./helloworld.protoset -d @ localhost:50051 helloworld.Greeter/SayHello
{
  &amp;quot;message&amp;quot;: &amp;quot;Hello World&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In both these examples, we passed the &lt;code&gt;-plaintext&lt;/code&gt; switch because our server is not running with TLS.&lt;/p&gt;
&lt;p&gt;If we were to &lt;a href=&#34;https://github.com/grpc/grpc-java/blob/master/documentation/server-reflection-tutorial.md&#34;&gt;turn on reflection&lt;/a&gt;, we will no longer need to depend on the &lt;code&gt;protoset&lt;/code&gt; file.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;&amp;gt; echo &#39;{&amp;quot;name&amp;quot;: &amp;quot;World&amp;quot;}&#39; | grpcurl -plaintext -d @ localhost:50051 helloworld.Greeter/SayHello
{
  &amp;quot;message&amp;quot;: &amp;quot;Hello World&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Overall, I like what the creator of grpcurl have done. The only thing I dont like is the fact that when reflection is turned off, we have to generate &lt;code&gt;protoset&lt;/code&gt; files. It would have been great if it could just look at the existing &lt;code&gt;proto&lt;/code&gt; files, which is what &lt;code&gt;polyglot&lt;/code&gt; does. We will look at polyglot in the next blog post.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>A Jackson and FreeBuilder quirk</title>
      <link>https://sadique.io/blog/2018/03/23/a-jackson-and-freebuilder-quirk/?utm_source=site&amp;utm_medium=feed</link>
      <pubDate>Fri, 23 Mar 2018 05:21:42 +0000</pubDate>
      
      <guid>https://sadique.io/blog/2018/03/23/a-jackson-and-freebuilder-quirk/?utm_source=site&amp;utm_medium=feed</guid>
      <description>&lt;p&gt;Jackson is a great tool to have in your tool set if you deal with JSON or XML. It facilitates easy serialization and de-serialization to and from Java classes with a convenient annotation based interface. With the same set of annotations, we can achieve both XML and JSON serialization and de-serialization. With Jackson&amp;rsquo;s &lt;code&gt;data-format-xml&lt;/code&gt; it is even possible to give the same Class a different JSON and XML representation.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;@JacksonXmlRootElement(localName = &amp;quot;user-account&amp;quot;)
@JsonRootName(&amp;quot;user&amp;quot;)
public class Account {
  private String name;
  private String emailAddress;

  @JsonProperty(&amp;quot;name&amp;quot;)
  @JacksonXmlProperty(localName = &amp;quot;name&amp;quot;)
  public String getName() {
    return name;
  }

  @JsonProperty(&amp;quot;email_address&amp;quot;)
  @JacksonXmlProperty(localName = &amp;quot;email-address&amp;quot;)
  public String getEmailAddress() {
    return emailAddress;
  }

  // ...
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;When this gets used, it does the serialization and de-serializaion to and from XML and JSON in different forms:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;jsonMapper = new ObjectMapper();
jsonMapper.configure(WRAP_ROOT_VALUE, true);
jsonMapper.configure(UNWRAP_ROOT_VALUE, true);
xmlMapper = new XmlMapper();

// ...

Account account = new Account(&amp;quot;John Doe&amp;quot;, &amp;quot;john@example.com&amp;quot;);

String jsonString = jsonMapper.writeValueAsString(account);
System.out.println(jsonString);
Account deSerializedAccount = jsonMapper.readValue(jsonString, Account.class);
assertEquals(account, deSerializedAccount);

String xmlString = xmlMapper.writeValueAsString(account);
System.out.println(xmlString);
deSerializedAccount = xmlMapper.readValue(xmlString, Account.class);
assertEquals(account, deSerializedAccount);
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;{&amp;quot;user&amp;quot;:{&amp;quot;name&amp;quot;:&amp;quot;John Doe&amp;quot;,&amp;quot;email_address&amp;quot;:&amp;quot;john@example.com&amp;quot;}}
&amp;lt;user-account&amp;gt;&amp;lt;name&amp;gt;John Doe&amp;lt;/name&amp;gt;&amp;lt;email-address&amp;gt;john@example.com&amp;lt;/email-address&amp;gt;&amp;lt;/user-account&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Things get really interesting when we introduce &lt;a href=&#34;http://freebuilder.inferred.org/&#34;&gt;FreeBuilder&lt;/a&gt;. FreeBuilder supports Jackson and we will be able to do serialization correctly. However, XML de-serialization does not work as expected.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;cksonXmlRootElement(localName = &amp;quot;user-account&amp;quot;)
@JsonRootName(&amp;quot;user&amp;quot;)
@FreeBuilder
@JsonDeserialize(builder = Account.Builder.class)
public interface Account {
  @JsonProperty(&amp;quot;name&amp;quot;)
  @JacksonXmlProperty(localName = &amp;quot;name&amp;quot;)
  String getName();

  @JsonProperty(&amp;quot;email_address&amp;quot;)
  @JacksonXmlProperty(localName = &amp;quot;email-address&amp;quot;)
  String getEmailAddress();

  class Builder extends Account_Builder {}
}
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;Account account = new Account.Builder()
    .setEmailAddress(&amp;quot;john@example.com&amp;quot;)
    .setName(&amp;quot;John Doe&amp;quot;)
    .build();

String jsonString = jsonMapper.writeValueAsString(account);
System.out.println(jsonString);
Account deSerializedAccount = jsonMapper.readValue(jsonString, Account.class);
assertEquals(account, deSerializedAccount);

String xmlString = xmlMapper.writeValueAsString(account);
System.out.println(xmlString);
deSerializedAccount = xmlMapper.readValue(xmlString, Account.class);
assertEquals(account, deSerializedAccount);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This will cause Jackson to throw an error while de-serializing XML, even though de-serializing to JSON works as expected.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;{&amp;quot;user&amp;quot;:{&amp;quot;name&amp;quot;:&amp;quot;John Doe&amp;quot;,&amp;quot;email_address&amp;quot;:&amp;quot;john@example.com&amp;quot;}}
&amp;lt;user-account&amp;gt;&amp;lt;name&amp;gt;John Doe&amp;lt;/name&amp;gt;&amp;lt;email-address&amp;gt;john@example.com&amp;lt;/email-address&amp;gt;&amp;lt;/user-account&amp;gt;

com.fasterxml.jackson.databind.exc.UnrecognizedPropertyException: Unrecognized field &amp;quot;email-address&amp;quot; (class in.sdqali.json.Account$Builder), not marked as ignorable (3 known properties: &amp;quot;emailAddress&amp;quot;, &amp;quot;email_address&amp;quot;, &amp;quot;name&amp;quot;])
 at [Source: (StringReader); line: 1, column: 83] (through reference chain: in.sdqali.json.Account$Builder[&amp;quot;email-address&amp;quot;])
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;After digging around, it turns out that FreeBuilder &lt;a href=&#34;https://github.com/inferred/FreeBuilder/blob/master/src/main/java/org/inferred/freebuilder/processor/JacksonSupport.java#L40&#34;&gt;keeps only&lt;/a&gt; the &lt;code&gt;@JsonProperty&lt;/code&gt; annotation on methods that it finds. This in turn causes the object created by the builder to have methods whose &lt;code&gt;@JacksonXmlProperty&lt;/code&gt; annotations are stripped of, which in turn causes Jackson to look for the camel-cased versions of the attribute names. I have opened a new &lt;a href=&#34;https://github.com/inferred/FreeBuilder/issues/294&#34;&gt;GitHub issue&lt;/a&gt; for this.&lt;/p&gt;
&lt;p&gt;Until this is resolved, if you use FreeBuilder and need to have different XML and JSON representation, you will have to write a custom Jackson &lt;a href=&#34;https://github.com/FasterXML/jackson-docs/wiki/JacksonHowToCustomSerializers&#34;&gt;Serializer&lt;/a&gt; and Deserializer.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Net::HTTP and the simplest of explanations</title>
      <link>https://sadique.io/blog/2018/03/22/nethttp-and-the-simplest-of-explanations/?utm_source=site&amp;utm_medium=feed</link>
      <pubDate>Thu, 22 Mar 2018 02:44:03 +0000</pubDate>
      
      <guid>https://sadique.io/blog/2018/03/22/nethttp-and-the-simplest-of-explanations/?utm_source=site&amp;utm_medium=feed</guid>
      <description>&lt;p&gt;&lt;em&gt;This blog post exists purely to remind myself that Ruby&amp;rsquo;s &lt;code&gt;Net::HTTP&lt;/code&gt; expects a &lt;code&gt;host&lt;/code&gt; and a &lt;code&gt;port&lt;/code&gt; as parameters when creating a new connection and not a &lt;code&gt;url&lt;/code&gt; string.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;This is a story about how many layers of abstractions and indirections one works through on a daily basis as a developer and the effort required to dive through these layers, all the while ignoring the simplest of explanations of why things may have gone wrong in the first place.&lt;/p&gt;
&lt;p&gt;At work, we have a homegrown orchestration tool that brings up Docker containers and configures dependencies and network access between them - essentially an abstraction over &lt;code&gt;docker-compose&lt;/code&gt;. In our continuous integration environment, this tool sets up all the different components of our system and then starts another container in which &lt;code&gt;RSpec&lt;/code&gt; based integration tests that exercise various inetractions between the components of the system are run.&lt;/p&gt;
&lt;p&gt;We added a new component and wanted a library used by the specs to use an API provided by this component. This essentially meant this for us:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Change our configurations so that the Docker container with the new component is started before the test container is started.&lt;/li&gt;
&lt;li&gt;Ensure that the test container can talk to the new component container.&lt;/li&gt;
&lt;li&gt;Tell the test container, through environment variables the &lt;code&gt;host&lt;/code&gt; and the &lt;code&gt;port&lt;/code&gt; of the new component.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;So, off we went and configured everything:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;env.NEWAPP_HOST=http://new-app.local
env.NEWAPP_PORT=1313
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We ran the tests and boom:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;SocketError (Failed to open TCP connection to http://new-app.local:1313 (getaddrinfo: nodename nor servname provided, or not known))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Well, that does not look right. We double check all the configurations and run the test again. Same result. May be we should be using a Ruby &lt;code&gt;Symbol&lt;/code&gt; instead of a &lt;code&gt;String&lt;/code&gt; in that particular config? May be. We try that, same result.&lt;/p&gt;
&lt;p&gt;At this point, we hop on to the test container and ping &lt;code&gt;new-app.local&lt;/code&gt;. It can connect.
What if the app is not available? We should totally &lt;code&gt;telnet&lt;/code&gt; it. Well, this container does not have &lt;code&gt;telnet&lt;/code&gt;. We can totally install it, right? Right. What kind of distro is this running? Well &lt;code&gt;cat /etc/*release*&lt;/code&gt;. Debian, huh? &lt;code&gt;apt-get install telnet&lt;/code&gt;. Wooh. Back to &lt;code&gt;telnet&lt;/code&gt; then. That looks good.&lt;/p&gt;
&lt;p&gt;At this point, the attention turns to the RSpec tests. What if the tests have some environment variables? Let&amp;rsquo;s debug it and look for things in Ruby&amp;rsquo;s &lt;code&gt;ENV&lt;/code&gt;. Hmmm, nothing interesting there. Can the Ruby process even connect to &lt;code&gt;new-app&lt;/code&gt;? We have &lt;code&gt;Faraday&lt;/code&gt;, let&amp;rsquo;s try that:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-irb&#34;&gt;&amp;gt; require &#39;faraday&#39;
=&amp;gt; true
&amp;gt; resp = Faraday.get &amp;quot;http://google.com&amp;quot;
&amp;gt; resp.status
200
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Okay, does the library we use for the test even use &lt;code&gt;Faraday&lt;/code&gt;? Let&amp;rsquo;s open the source code for that and poke around. Nah, it uses &lt;code&gt;Net::Http&lt;/code&gt;. Let&amp;rsquo;s try the example from &lt;a href=&#34;https://ruby-doc.org/stdlib-2.5.0/libdoc/net/http/rdoc/Net/HTTP.html&#34;&gt;it&amp;rsquo;s documentation&lt;/a&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-irb&#34;&gt;&amp;gt; require &#39;net/http&#39;
=&amp;gt; true
&amp;gt; Net::HTTP.get_response(URI(&amp;quot;http://new-app.local:1313&amp;quot;))
=&amp;gt; #&amp;lt;Net::HTTPOK 200 OK readbody=true&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Looks good. Well, wait! Our library uses &lt;code&gt;Net::HTTP.new&lt;/code&gt; to create a connection. Let&amp;rsquo;s try that:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-irb&#34;&gt;&amp;gt; conn = Net::HTTP.new(&amp;quot;http://new-app.local&amp;quot;, 1313)
=&amp;gt; #&amp;lt;Net::HTTP http://new-app.local:1313 open=false&amp;gt;
&amp;gt; conn.get(&amp;quot;/&amp;quot;)
Traceback (most recent call last):
.
.
.
SocketError (Failed to open TCP connection to http://new-app.local:1313 (getaddrinfo: nodename nor servname provided, or not known))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;At this point, we are covered in a mix of disappointment and excitement. We are annoyed that things are not working. But, may be, may be we have uncovered some obscure bug somewhere in the toolset? We would learn later that this is the point where we should have known what&amp;rsquo;s up? But we didn&amp;rsquo;t and the story continues.&lt;/p&gt;
&lt;p&gt;At this point, we ping the Slack channels of the teams involved in building the library we consume. They have not seen this before. Someone suggests that they have had issues with Ruby inside Docker containers. We finally find a GitHub issue for a different project where someone encountered their container setting the &lt;code&gt;HTTP_PROXY&lt;/code&gt; env variable and that causing &lt;code&gt;Net::HTTP&lt;/code&gt; to fail. We pore over everything to make sure that there is no proxy set. What now?&lt;/p&gt;
&lt;p&gt;What if we attempt to connect to the new app from a Ruby process running on one of the other 10 containers we run?&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;&amp;gt; docker exec -it 51dbf9f75ca8 ruby -e &#39;require &amp;quot;net/http&amp;quot;; conn = Net::HTTP.new(&amp;quot;http://new-app.local&amp;quot;, 1313); conn.get(&amp;quot;/&amp;quot;)&#39;
Traceback (most recent call last):
.
.
.
SocketError (Failed to open TCP connection to http://new-app.local:1313 (getaddrinfo: nodename nor servname provided, or not known))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;That is interesting, isn&amp;rsquo;t it? Is it happening to only our systems? What if we just tried to hit Google?&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;&amp;gt; docker exec -it 51dbf9f75ca8 ruby -e &#39;require &amp;quot;net/http&amp;quot;; conn = Net::HTTP.new(&amp;quot;http://google.com&amp;quot;, 80); conn.get(&amp;quot;/&amp;quot;)&#39;
Traceback (most recent call last):
.
.
.
SocketError (Failed to open TCP connection to http://google.com:80 (getaddrinfo: nodename nor servname provided, or not known))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;What if somehow our orchestration tool or containers created by us are causing it? Let&amp;rsquo;s try a random container from DockerHub:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;&amp;gt; docker run -it ruby:2.5-slim ruby -e &#39;require &amp;quot;net/http&amp;quot;; conn = Net::HTTP.new(&amp;quot;http://google.com&amp;quot;,80); conn.get(&amp;quot;/&amp;quot;)&#39;
Traceback (most recent call last):
.
.
.
SocketError (Failed to open TCP connection to http://google.com:80 (getaddrinfo: nodename nor servname provided, or not known))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;At this point, light bulbs are beginning to go off. Let&amp;rsquo;s try this on our laptops? Same result. And then it struck us. It says it can&amp;rsquo;t open a TCP connection to a URL with &lt;code&gt;http&lt;/code&gt; in it.  Of course, it cant. It should be looking for &lt;code&gt;google.com&lt;/code&gt;, should not it? Yes:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-irb&#34;&gt;&amp;gt; docker run -it ruby:2.5-slim ruby -e &#39;require &amp;quot;net/http&amp;quot;; conn = Net::HTTP.new(&amp;quot;google.com&amp;quot;, 80); res = conn.get(&amp;quot;/&amp;quot;); puts res.code&#39;
301
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And with a lot of excitement and some shame, we realize that the library really meant &lt;code&gt;host&lt;/code&gt; when it asked for the &lt;code&gt;NEWAPP_HOST&lt;/code&gt; environment variable.&lt;/p&gt;
&lt;p&gt;I don&amp;rsquo;t think there are any big lessons in this story other than that, sometimes the simplest explanation of a problems makes a lot more sense than you would think it does. Also, if you ever use &lt;code&gt;Net::HTTP.new&lt;/code&gt;, remember that it expects you to provide a &lt;code&gt;host&lt;/code&gt; as the first param, not a URL.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Python URL manipulation revisited</title>
      <link>https://sadique.io/blog/2017/09/26/python-url-manipulation-revisited/?utm_source=site&amp;utm_medium=feed</link>
      <pubDate>Tue, 26 Sep 2017 04:22:39 +0000</pubDate>
      
      <guid>https://sadique.io/blog/2017/09/26/python-url-manipulation-revisited/?utm_source=site&amp;utm_medium=feed</guid>
      <description>&lt;p&gt;My &lt;a href=&#34;https://sadique.io/blog/2017/08/17/uploading-a-standalone-artifact-to-nexus-3/&#34;&gt;last blog post&lt;/a&gt; about publishing standalone files to Nexus repositories prompted me to revisit URL manipulation in Python. When I did this &lt;a href=&#34;https://sadique.io/blog/2013/09/26/decomposing-urls-in-python/&#34;&gt;the last time&lt;/a&gt;, I used Python stand library&amp;rsquo;s &lt;code&gt;urlparse&lt;/code&gt; and it did the job. This time around, I needed to do a different kind of manipulation. Given a URL, I had to set credentials on it.&lt;/p&gt;
&lt;p&gt;I started at &lt;code&gt;urlparse&lt;/code&gt; and soon realized that Python3 moved this module to &lt;a href=&#34;https://docs.python.org/3/library/urllib.parse.html&#34;&gt;urllib.parse&lt;/a&gt;. That is not too bad, I thought. After playing around with it, it became clear that &lt;code&gt;urllib.parse&lt;/code&gt; can&amp;rsquo;t manipulate credentials in a URL.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;In [1]: from urllib import parse

In [2]: url = parse.urlparse(&#39;http://example.com&#39;)

In [3]: print(url)
ParseResult(scheme=&#39;http&#39;, netloc=&#39;example.com&#39;, path=&#39;&#39;, params=&#39;&#39;, query=&#39;&#39;, fragment=&#39;&#39;)

In [4]: url.username = &amp;quot;username&amp;quot;
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
&amp;lt;ipython-input-4-60e52fe02603&amp;gt; in &amp;lt;module&amp;gt;()
----&amp;gt; 1 url.username = &amp;quot;username&amp;quot;

AttributeError: can&#39;t set attribute

In [5]: url.password = &amp;quot;password&amp;quot;
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
&amp;lt;ipython-input-5-4f64c7192b99&amp;gt; in &amp;lt;module&amp;gt;()
----&amp;gt; 1 url.password = &amp;quot;password&amp;quot;

AttributeError: can&#39;t set attribute

In [6]: url.username == None
Out[6]: True

In [7]: url.password == None
Out[7]: True
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;After spending time with various URL manipulation libraries in Python, &lt;a href=&#34;https://github.com/gruns/furl&#34;&gt;furl&lt;/a&gt; was the only library that I found to be capable of this seemingly simple and common enough operation.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;In [1]: from furl import furl

In [2]: url = furl(&#39;http://example.com&#39;)

In [3]: url
Out[3]: furl(&#39;http://example.com&#39;)

In [4]: url.password = &amp;quot;password&amp;quot;

In [5]: url.username = &amp;quot;user&amp;quot;

In [6]: url.tostr()
Out[6]: &#39;http://user:password@example.com&#39;
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Uploading a standalone artifact to Nexus 3</title>
      <link>https://sadique.io/blog/2017/08/18/uploading-a-standalone-artifact-to-nexus-3/?utm_source=site&amp;utm_medium=feed</link>
      <pubDate>Fri, 18 Aug 2017 04:00:43 +0000</pubDate>
      
      <guid>https://sadique.io/blog/2017/08/18/uploading-a-standalone-artifact-to-nexus-3/?utm_source=site&amp;utm_medium=feed</guid>
      <description>&lt;p&gt;This is one of those &amp;ldquo;I had to figure out how to do this today, so the next time I google this, I have a place to look&amp;rdquo; blog posts.
Today, I had to upload a zip file as a build artifact to our Nexus 3 repository. The zip file had been generated by custom shell scripts that did not have a Maven, Ivy or Gradle projects to wrap them.&lt;/p&gt;
&lt;p&gt;The obvious way to do this seemed like using the Nexus 3 REST API, invoked like this:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;curl -v -u &amp;lt;username&amp;gt;:&amp;lt;password&amp;gt; \
   --upload-file artifact.zip \
   https://&amp;lt;nexus-server&amp;gt;/repository/maven-releases/com/example/artifact/1.0.0/artifact-1.0.0.zip
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This works and the file is available in the repository. However, this method has the following shortcomings:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;There will not be a &lt;code&gt;POM&lt;/code&gt; file generated for this artifact.&lt;/li&gt;
&lt;li&gt;The maven metadata associated with this artifact will not be updated.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Using Maven Deploy Plugin&amp;rsquo;s &lt;a href=&#34;http://maven.apache.org/plugins/maven-deploy-plugin/deploy-file-mojo.html&#34;&gt;deploy file mojo&lt;/a&gt; in this situation will help us satisfy the above requirements. The mojo is capable of running in arbitrary directories without the need for a &lt;code&gt;pom.xml&lt;/code&gt; to be present. However, it does expect you to specify authentication parameters in a &lt;code&gt;settings.xml&lt;/code&gt; file. In my situation, I did not want to write credentials in a &lt;code&gt;settings.xml&lt;/code&gt;, so I had to improvise.&lt;/p&gt;
&lt;p&gt;This is what I ended up using and it works like a charm:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;mvn deploy:deploy-file \
    -DgroupId=com.example \
    -DartifactId=artifact \
    -Dversion=1.0.0 \
    -Dpackaging=zip \
    -Dfile=artifact.zip \
    -DgeneratePom=true \
    -DupdateReleaseInfo=true \
    -Durl=&amp;quot;https://${NEXUS_USERNAME}:${NEXUS_PASSWORD}@&amp;lt;nexus-server&amp;gt;/repository/maven-releases/&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
  </channel>
</rss>
